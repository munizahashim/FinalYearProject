# -*- coding: utf-8 -*-
"""Bishkek Home Prices Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QBQXlrWQ12XqKYF-KAFyccmdyZ_4WpN-
"""

# link to github for the dataset: https://www.kaggle.com/datasets/azamatkibekbaev/house-price-bishkek?group=owned

import pandas as pd
df = pd.read_csv('house_kg_10K_ads.csv')

df.head(10)

df.shape

"""## 1. Data cleaning"""

# no of data types in the data
obj = (df.dtypes == 'object')
object_cols = list(obj[obj].index)
print("Categorical variables:",len(object_cols))

int_ = (df.dtypes == 'int')
num_cols = list(int_[int_].index)
print("Integer variables:",len(num_cols))

fl = (df.dtypes == 'float')
fl_cols = list(fl[fl].index)
print("Float variables:",len(fl_cols))

print("=============================")
print(df.isnull().sum())

print("=============================")
print(df.nunique())

#dropping the nulll values
df.dropna(subset=['district'], inplace=True)

# removing the duplicate rows
duplicate_rows = df.duplicated()
print(duplicate_rows.sum())

df['date_year'] = pd.to_datetime(df['date']).dt.year
df.head(1)

"""## 2. Exploratory analysis


"""

df['price'].hist()
# df.loc[df['price'] < df['price'].mean() + 2 * df['price'].std(), 'price'].hist()

# Numeric (String): Representing the counts of rooms.
# String (Categorical): Representing special categories like "6 и более" and "свободная планировка".

unique_rooms = df['rooms'].unique()
unique_rooms

unique_rooms = df['rooms'].value_counts()
unique_rooms

# Replace 'свободная планировка' with 0 (free layout)
df.loc[df['rooms'] == "свободная планировка", 'rooms'] = 0 # free layout


# Replace '6 и более' with 6 (6 and more)
df.loc[df['rooms'] == "6 и более", 'rooms'] = 6 # 6 and more

# Convert the 'rooms' column to integer data type
df["rooms"] = df["rooms"].astype(int)

df.plot.scatter('rooms', 'price')

import matplotlib.pyplot as plt

df['is_top_floor'] = (df['floor'] == df['floors']) & (df['floor'] != 1)
df['is_bottom_floor'] = (df['floor'] == 1) & (df['floor'] != df['floors'])

# Bar Plot - Average Price by Floor Type
avg_price_by_floor_type = df.groupby(['is_top_floor', 'is_bottom_floor'])['price'].mean()
avg_price_by_floor_type.plot(kind='bar', color='blue')
plt.xlabel('Floor Type')
plt.ylabel('Average Price')
plt.xticks([0, 1, 2], ['Not Top/Bottom', 'Top Floor', 'Bottom Floor'])  # Corrected xticks
plt.title('Average Price Comparison by Floor Type')
plt.show()

min_price_by_district = df.groupby('district')['price'].min()

# Calculate the total minimum price
total_min_price = min_price_by_district.sum()

# Calculate the proportion of each district's minimum price relative to the total minimum price
proportions = min_price_by_district / total_min_price

# Plotting a pie chart
plt.pie(proportions, labels=min_price_by_district.index, autopct='%1.1f%%', startangle=140, colors=['blue','red', 'green', 'orange'])
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.title('Proportion of Minimum Price by District')
plt.show()

top_n = 10  # Number of top micro districts to display
top_micro_districts = df.groupby('square')['price'].mean().sort_values(ascending=False).head(top_n)
top_micro_districts.plot(kind='bar')
plt.xlabel('square')
plt.ylabel('Average Price')
plt.title('Top Micro Districts by Price')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Create a heatmap to visualize correlations in the DataFrame (correlation coefficient)
plt.figure(figsize=(21, 12))
sns.heatmap(df.corr(),
            cmap = 'BrBG',
            fmt = '.2f',
            linewidths = 2,
            annot = True)

# Assuming you've loaded your data into the 'data' DataFrame

def show_graphs():
  # Specify the columns for the pair plot
  columns_to_plot = ["price",
                    "m2_price",
                    "square",
                    "rooms",
                    "district",
                    "building_type",
                    "floor",
                    "floors",
                    "year",
                    "source",
                    "condition"]

  # Set the style for the plot
  sns.set(style="ticks")

  # # Create a pair plot to visualize relationships between pairs of variables
  sns.pairplot(df[columns_to_plot], diag_kind="kde", markers="o", plot_kws={"color": "orange"})

  # Set labels for the variables
  plt.subplots_adjust(top=0.95)  # Adjust the title position
  plt.suptitle("Pairplot of variables", fontsize=16)
  plt.show()

show_graphs()

"""## Feature Engineering"""

print(f"Min year: {df['year'].min()}")
print(f"Max year: {df['year'].max()}")

df['year'].fillna(0, inplace=True)
df["year"] = df["year"].astype(int)

year_bin_names = ['missing', '1951-1960', '1961-1970', '1971-1980', '1981-1990',
                  '1991-2000', '2001-2010', '2011-2014', '2015-2020', '2021-2025']
year_bin = [0, 1950,1960,1970,1980,1990,2000,2010,2014,2020,2025]
df['year'].fillna('missing', inplace=True)
df['year_bin'] = pd.cut(df['year'], bins=year_bin, labels=year_bin_names, right=True)

df.head(1)

df['max_price_micro_district'] = df.groupby('micro_district')['price'].transform('max')
df['max_price_micro_district'].fillna(0, inplace=True)

# One Hot Encoding
def encode_and_bind(df, encode_data):
  dummies = pd.get_dummies(df[[encode_data]])
  res = pd.concat([df, dummies], axis=1)
  cols = dummies.columns.tolist()
  return (res, cols)

df, col = encode_and_bind(df, 'district')
df, col = encode_and_bind(df, 'building_type')
df, col = encode_and_bind(df, 'condition')
df, col = encode_and_bind(df, 'source')
df, col = encode_and_bind(df, 'year_bin')

independent_variables = ["square", "rooms", "floors", "floor", "date_year", 'max_price_micro_district',
                         "district_Ленинский район", "district_Октябрьский район",
                         "district_Первомайский район", "district_Свердловский район",
                         "building_type_кирпичный", "building_type_монолитный",
                         "building_type_панельный" ,'condition_под самоотделку (ПСО)',
                         'condition_хорошее', 'condition_среднее', 'condition_не достроено',
                         'condition_требует ремонта', 'condition_черновая отделка',
                         'condition_свободная планировка', 'source_Site', 'source_Android',
                         'source_iOS', 'year_bin_1951-1960', 'year_bin_1961-1970', 'year_bin_1971-1980', 'year_bin_1981-1990', 'year_bin_1991-2000', 'year_bin_2001-2010',
                         'year_bin_2011-2014', 'year_bin_2015-2020', 'year_bin_2021-2025'
                         ]
dependent_variable = ["price"]
# 32
#standardization process on the selected columns in the DataFrame
df[independent_variables] = (df[independent_variables] - df[independent_variables].mean()) / (df[independent_variables].std())
df[dependent_variable] = (df[dependent_variable] - df[dependent_variable].mean()) / (df[dependent_variable].std())

import statsmodels.api as sm
# Our features are now ready! Set up X and y based on dependent and independent variables defined, adding a constant to the list of independent variables
X = df[independent_variables]
X = sm.add_constant(X)
y = df[dependent_variable]

"""## Modeling phase"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)

"""## 1st Model LinearRegression"""

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)

"""## evaluating LinearRegression Model"""

y_pred = regressor.predict(X_test)
y_pred

reg_model = sm.OLS(y_train, X_train)
result = reg_model.fit()
print(result.summary())

from sklearn.metrics import r2_score, mean_squared_error

# Calculate r squared for the model using test data
y_pred = result.predict(X_test)
r2_score(y_test, y_pred)

# Calculate the MSE using test data
mean_squared_error(y_test, y_pred)

import matplotlib.pyplot as plt

# Assuming you have y_test (real results) and y_pred (predicted results) defined

plt.figure(figsize=(10, 6))

# Plot real values in blue
plt.scatter(y_test, y_test, color='blue', alpha=0.5, label='Real Values')

# Plot predicted values in red
plt.scatter(y_test, y_pred, color='red', alpha=0.5, label='Predicted Values')

plt.xlabel('Real Prices')
plt.ylabel('Predicted Prices')
plt.title('Real vs. Predicted Prices')
plt.legend()
plt.show()

"""## 2nd Model RandomForestRegressor"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Assume you have your data as X (features) and y (target values)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Instantiate the Random Forest regressor
regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model on the training data
regressor.fit(X_train, y_train)

# Make predictions on the test data
y_pred = regressor.predict(X_test)

# Calculate the mean squared error to evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")


from sklearn.metrics import r2_score, mean_squared_error

# Calculate r squared for the model using test data
y_pred = result.predict(X_test)

r_squared = r2_score(y_test, y_pred)
print(f"R Squared Value is: {r_squared}")

import matplotlib.pyplot as plt

# Assuming you have y_test (real results) and y_pred (predicted results) defined

plt.figure(figsize=(10, 6))

# Plot real values in blue
plt.scatter(y_test, y_test, color='blue', alpha=0.5, label='Real Values')

# Plot predicted values in red
plt.scatter(y_test, y_pred, color='red', alpha=0.5, label='Predicted Values')

plt.xlabel('Real Prices')
plt.ylabel('Predicted Prices')
plt.title('Real vs. Predicted Prices')
plt.legend()
plt.show()

"""## 3rd Model DecisionTreeRegressor"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

# Assume you have your data as X (features) and y (target values)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Instantiate the Decision Tree regressor
regressor = DecisionTreeRegressor(random_state=42)

# Fit the model on the training data
regressor.fit(X_train, y_train)

# Make predictions on the test data
y_pred = regressor.predict(X_test)

# Calculate the mean squared error to evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

r_squared = r2_score(y_test, y_pred)
print(f"R Squared Value is: {r_squared}")

import matplotlib.pyplot as plt

# Assuming you have y_test (real results) and y_pred (predicted results) defined

plt.figure(figsize=(10, 6))

# Plot real values in blue
plt.scatter(y_test, y_test, color='blue', alpha=0.5, label='Real Values')

# Plot predicted values in red
plt.scatter(y_test, y_pred, color='red', alpha=0.5, label='Predicted Values')

plt.xlabel('Real Prices')
plt.ylabel('Predicted Prices')
plt.title('Real vs. Predicted Prices')
plt.legend()
plt.show()